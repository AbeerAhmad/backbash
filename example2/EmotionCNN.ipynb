{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e64a70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d479ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('fer2013.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cadb2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       emotion                                             pixels        Usage\n",
      "0            0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...     Training\n",
      "1            0  151 150 147 155 148 133 111 140 170 174 182 15...     Training\n",
      "2            2  231 212 156 164 174 138 161 173 182 200 106 38...     Training\n",
      "3            4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...     Training\n",
      "4            6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...     Training\n",
      "...        ...                                                ...          ...\n",
      "35882        6  50 36 17 22 23 29 33 39 34 37 37 37 39 43 48 5...  PrivateTest\n",
      "35883        3  178 174 172 173 181 188 191 194 196 199 200 20...  PrivateTest\n",
      "35884        0  17 17 16 23 28 22 19 17 25 26 20 24 31 19 27 9...  PrivateTest\n",
      "35885        3  30 28 28 29 31 30 42 68 79 81 77 67 67 71 63 6...  PrivateTest\n",
      "35886        2  19 13 14 12 13 16 21 33 50 57 71 84 97 108 122...  PrivateTest\n",
      "\n",
      "[35887 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "258a29f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height = 48, 48\n",
    "datapoints = dataset['pixels'].tolist()\n",
    "X = []\n",
    "for xseq in datapoints:\n",
    "    xvals = [int(xp) for xp in xseq.split(' ')]\n",
    "    xvals = np.asarray(xvals).reshape(width, height)\n",
    "    X.append(xvals.astype('float32'))\n",
    "\n",
    "X = np.asarray(X)\n",
    "X = np.expand_dims(X, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7ef43e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Features in dataset: 48\n",
      "Number of Labels in dataset: 7\n",
      "Number of examples in dataset:35887\n",
      "X stored as dataX.npy and y stored as labels.npy \n"
     ]
    }
   ],
   "source": [
    "y = pd.get_dummies(dataset['emotion']).to_numpy()\n",
    "\n",
    "#storing them using numpy\n",
    "np.save('dataX', X)\n",
    "np.save('labels', y)\n",
    "\n",
    "print(\"Number of Features in dataset: \"+str(len(X[0])))\n",
    "print(\"Number of Labels in dataset: \"+ str(len(y[0])))\n",
    "print(\"Number of examples in dataset:\"+str(len(X)))\n",
    "print(\"X stored as dataX.npy and y stored as labels.npy \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3a018af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f1c04b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 48\n",
    "num_labels = 7\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "width, height = 48, 48\n",
    "\n",
    "x = np.load('./dataX.npy')\n",
    "y = np.load('./labels.npy')\n",
    "\n",
    "x -= np.mean(x, axis=0)\n",
    "x /= np.std(x, axis=0)\n",
    "\n",
    "#splitting into training, validation and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1, random_state=41)\n",
    "\n",
    "#saving the test samples to be used later\n",
    "np.save('Xtest', X_test)\n",
    "np.save('ytest', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "740907e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-11 00:46:13.164171: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 46, 46, 48)        480       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 46, 46, 48)        20784     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 46, 46, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 23, 23, 48)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 23, 23, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 23, 23, 96)        41568     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 23, 23, 96)        384       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 23, 23, 96)        83040     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 23, 23, 96)        384       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 96)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 11, 11, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 11, 11, 192)       166080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 11, 11, 192)       768       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 11, 11, 192)       331968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 11, 11, 192)       768       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 192)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 5, 192)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 5, 5, 384)         663936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 5, 5, 384)         1536      \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 5, 5, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 5, 5, 384)         1536      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 384)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2, 2, 384)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 384)               590208    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 192)               73920     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 96)                18528     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 679       \n",
      "=================================================================\n",
      "Total params: 3,324,247\n",
      "Trainable params: 3,321,463\n",
      "Non-trainable params: 2,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(num_features, kernel_size=(3, 3), activation='relu', input_shape=(width, height, 1), data_format='channels_last', kernel_regularizer=l2(0.01)))\n",
    "model.add(Conv2D(num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(2*2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(2*2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(2*2*2*num_features, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(2*2*num_features, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(2*num_features, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_labels, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c145f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n",
      "2021-12-11 00:46:19.420619: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "455/455 [==============================] - 758s 2s/step - loss: 1.9747 - accuracy: 0.2190 - val_loss: 1.8134 - val_accuracy: 0.2594\n",
      "Epoch 2/100\n",
      "455/455 [==============================] - 729s 2s/step - loss: 1.8442 - accuracy: 0.2429 - val_loss: 1.8032 - val_accuracy: 0.2607\n",
      "Epoch 3/100\n",
      "455/455 [==============================] - 676s 1s/step - loss: 1.8145 - accuracy: 0.2522 - val_loss: 1.7440 - val_accuracy: 0.3000\n",
      "Epoch 4/100\n",
      "455/455 [==============================] - 678s 1s/step - loss: 1.7447 - accuracy: 0.2864 - val_loss: 1.6297 - val_accuracy: 0.3248\n",
      "Epoch 5/100\n",
      "455/455 [==============================] - 685s 2s/step - loss: 1.6522 - accuracy: 0.3326 - val_loss: 1.5041 - val_accuracy: 0.4115\n",
      "Epoch 6/100\n",
      "455/455 [==============================] - 679s 1s/step - loss: 1.5567 - accuracy: 0.3802 - val_loss: 1.4658 - val_accuracy: 0.4046\n",
      "Epoch 7/100\n",
      "455/455 [==============================] - 672s 1s/step - loss: 1.4929 - accuracy: 0.4095 - val_loss: 1.3727 - val_accuracy: 0.4477\n",
      "Epoch 8/100\n",
      "455/455 [==============================] - 668s 1s/step - loss: 1.4523 - accuracy: 0.4250 - val_loss: 1.3728 - val_accuracy: 0.4560\n",
      "Epoch 9/100\n",
      "455/455 [==============================] - 666s 1s/step - loss: 1.4187 - accuracy: 0.4418 - val_loss: 1.3217 - val_accuracy: 0.4811\n",
      "Epoch 10/100\n",
      "455/455 [==============================] - 673s 1s/step - loss: 1.3803 - accuracy: 0.4660 - val_loss: 1.2817 - val_accuracy: 0.5025\n",
      "Epoch 11/100\n",
      "455/455 [==============================] - 670s 1s/step - loss: 1.3477 - accuracy: 0.4834 - val_loss: 1.2454 - val_accuracy: 0.5322\n",
      "Epoch 12/100\n",
      "455/455 [==============================] - 669s 1s/step - loss: 1.3274 - accuracy: 0.4939 - val_loss: 1.2222 - val_accuracy: 0.5437\n",
      "Epoch 13/100\n",
      "455/455 [==============================] - 672s 1s/step - loss: 1.2937 - accuracy: 0.5040 - val_loss: 1.2203 - val_accuracy: 0.5406\n",
      "Epoch 14/100\n",
      "455/455 [==============================] - 673s 1s/step - loss: 1.2761 - accuracy: 0.5176 - val_loss: 1.1943 - val_accuracy: 0.5505\n",
      "Epoch 15/100\n",
      "455/455 [==============================] - 673s 1s/step - loss: 1.2460 - accuracy: 0.5288 - val_loss: 1.1765 - val_accuracy: 0.5536\n",
      "Epoch 16/100\n",
      "455/455 [==============================] - 676s 1s/step - loss: 1.2378 - accuracy: 0.5346 - val_loss: 1.1555 - val_accuracy: 0.5669\n",
      "Epoch 17/100\n",
      "455/455 [==============================] - 679s 1s/step - loss: 1.2113 - accuracy: 0.5458 - val_loss: 1.1739 - val_accuracy: 0.5734\n",
      "Epoch 18/100\n",
      "455/455 [==============================] - 672s 1s/step - loss: 1.1980 - accuracy: 0.5597 - val_loss: 1.1304 - val_accuracy: 0.5759\n",
      "Epoch 19/100\n",
      "455/455 [==============================] - 675s 1s/step - loss: 1.1721 - accuracy: 0.5662 - val_loss: 1.1104 - val_accuracy: 0.5845\n",
      "Epoch 20/100\n",
      "455/455 [==============================] - 672s 1s/step - loss: 1.1540 - accuracy: 0.5747 - val_loss: 1.0818 - val_accuracy: 0.5985\n",
      "Epoch 21/100\n",
      "455/455 [==============================] - 671s 1s/step - loss: 1.1417 - accuracy: 0.5805 - val_loss: 1.1228 - val_accuracy: 0.5954\n",
      "Epoch 22/100\n",
      "455/455 [==============================] - 673s 1s/step - loss: 1.1231 - accuracy: 0.5862 - val_loss: 1.0752 - val_accuracy: 0.6062\n",
      "Epoch 23/100\n",
      "455/455 [==============================] - 670s 1s/step - loss: 1.1182 - accuracy: 0.5918 - val_loss: 1.1012 - val_accuracy: 0.5923\n",
      "Epoch 24/100\n",
      "455/455 [==============================] - 677s 1s/step - loss: 1.0952 - accuracy: 0.6038 - val_loss: 1.0778 - val_accuracy: 0.6080\n",
      "Epoch 25/100\n",
      "455/455 [==============================] - 667s 1s/step - loss: 1.0775 - accuracy: 0.6070 - val_loss: 1.0298 - val_accuracy: 0.6214\n",
      "Epoch 26/100\n",
      "455/455 [==============================] - 673s 1s/step - loss: 1.0608 - accuracy: 0.6130 - val_loss: 1.0516 - val_accuracy: 0.6084\n",
      "Epoch 27/100\n",
      "455/455 [==============================] - 686s 2s/step - loss: 1.0497 - accuracy: 0.6193 - val_loss: 1.0416 - val_accuracy: 0.6074\n",
      "Epoch 28/100\n",
      "455/455 [==============================] - 690s 2s/step - loss: 1.0370 - accuracy: 0.6253 - val_loss: 1.0623 - val_accuracy: 0.6176\n",
      "Epoch 29/100\n",
      "455/455 [==============================] - 674s 1s/step - loss: 1.0201 - accuracy: 0.6299 - val_loss: 1.0345 - val_accuracy: 0.6245\n",
      "Epoch 30/100\n",
      "455/455 [==============================] - 668s 1s/step - loss: 1.0090 - accuracy: 0.6354 - val_loss: 1.0373 - val_accuracy: 0.6232\n",
      "Epoch 31/100\n",
      "455/455 [==============================] - 667s 1s/step - loss: 0.9902 - accuracy: 0.6434 - val_loss: 1.0569 - val_accuracy: 0.6245\n",
      "Epoch 32/100\n",
      "455/455 [==============================] - 679s 1s/step - loss: 0.9744 - accuracy: 0.6474 - val_loss: 1.0486 - val_accuracy: 0.6288\n",
      "Epoch 33/100\n",
      "455/455 [==============================] - 680s 1s/step - loss: 0.9656 - accuracy: 0.6504 - val_loss: 1.0142 - val_accuracy: 0.6359\n",
      "Epoch 34/100\n",
      "455/455 [==============================] - 668s 1s/step - loss: 0.9607 - accuracy: 0.6532 - val_loss: 1.0154 - val_accuracy: 0.6238\n",
      "Epoch 35/100\n",
      "455/455 [==============================] - 667s 1s/step - loss: 0.9421 - accuracy: 0.6561 - val_loss: 1.0409 - val_accuracy: 0.6235\n",
      "Epoch 36/100\n",
      "455/455 [==============================] - 668s 1s/step - loss: 0.9271 - accuracy: 0.6654 - val_loss: 1.0230 - val_accuracy: 0.6347\n",
      "Epoch 37/100\n",
      "455/455 [==============================] - 675s 1s/step - loss: 0.9160 - accuracy: 0.6669 - val_loss: 1.0258 - val_accuracy: 0.6319\n",
      "Epoch 38/100\n",
      "455/455 [==============================] - 681s 1s/step - loss: 0.9054 - accuracy: 0.6750 - val_loss: 1.0607 - val_accuracy: 0.6297\n",
      "Epoch 39/100\n",
      "455/455 [==============================] - 666s 1s/step - loss: 0.8990 - accuracy: 0.6757 - val_loss: 1.0172 - val_accuracy: 0.6446\n",
      "Epoch 40/100\n",
      "455/455 [==============================] - 666s 1s/step - loss: 0.8888 - accuracy: 0.6844 - val_loss: 1.0379 - val_accuracy: 0.6359\n",
      "Epoch 41/100\n",
      "455/455 [==============================] - 673s 1s/step - loss: 0.8837 - accuracy: 0.6815 - val_loss: 0.9990 - val_accuracy: 0.6418\n",
      "Epoch 42/100\n",
      "455/455 [==============================] - 675s 1s/step - loss: 0.8664 - accuracy: 0.6886 - val_loss: 0.9909 - val_accuracy: 0.6412\n",
      "Epoch 43/100\n",
      "455/455 [==============================] - 675s 1s/step - loss: 0.8558 - accuracy: 0.6918 - val_loss: 1.0166 - val_accuracy: 0.6508\n",
      "Epoch 44/100\n",
      "455/455 [==============================] - 668s 1s/step - loss: 0.8508 - accuracy: 0.6946 - val_loss: 1.0020 - val_accuracy: 0.6492\n",
      "Epoch 45/100\n",
      "455/455 [==============================] - 680s 1s/step - loss: 0.8314 - accuracy: 0.7019 - val_loss: 1.0202 - val_accuracy: 0.6449\n",
      "Epoch 46/100\n",
      "455/455 [==============================] - 672s 1s/step - loss: 0.8285 - accuracy: 0.7033 - val_loss: 0.9977 - val_accuracy: 0.6517\n",
      "Epoch 47/100\n",
      "455/455 [==============================] - 665s 1s/step - loss: 0.8182 - accuracy: 0.7083 - val_loss: 1.0300 - val_accuracy: 0.6424\n",
      "Epoch 48/100\n",
      "455/455 [==============================] - 671s 1s/step - loss: 0.8039 - accuracy: 0.7107 - val_loss: 1.0228 - val_accuracy: 0.6464\n",
      "Epoch 49/100\n",
      "455/455 [==============================] - 672s 1s/step - loss: 0.7982 - accuracy: 0.7179 - val_loss: 1.0536 - val_accuracy: 0.6467\n",
      "Epoch 50/100\n",
      "455/455 [==============================] - 669s 1s/step - loss: 0.7896 - accuracy: 0.7183 - val_loss: 1.0288 - val_accuracy: 0.6526\n",
      "Epoch 51/100\n",
      "455/455 [==============================] - 670s 1s/step - loss: 0.7782 - accuracy: 0.7255 - val_loss: 1.0179 - val_accuracy: 0.6458\n",
      "Epoch 52/100\n",
      "455/455 [==============================] - 667s 1s/step - loss: 0.7800 - accuracy: 0.7244 - val_loss: 1.0096 - val_accuracy: 0.6563\n",
      "Epoch 53/100\n",
      "455/455 [==============================] - 669s 1s/step - loss: 0.7631 - accuracy: 0.7296 - val_loss: 1.0493 - val_accuracy: 0.6533\n",
      "Epoch 54/100\n",
      "455/455 [==============================] - 685s 2s/step - loss: 0.7503 - accuracy: 0.7307 - val_loss: 1.0502 - val_accuracy: 0.6576\n",
      "Epoch 55/100\n",
      "455/455 [==============================] - 677s 1s/step - loss: 0.7397 - accuracy: 0.7363 - val_loss: 1.0447 - val_accuracy: 0.6644\n",
      "Epoch 56/100\n",
      "455/455 [==============================] - 674s 1s/step - loss: 0.7431 - accuracy: 0.7364 - val_loss: 1.0385 - val_accuracy: 0.6591\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455/455 [==============================] - 673s 1s/step - loss: 0.7261 - accuracy: 0.7445 - val_loss: 1.0326 - val_accuracy: 0.6536\n",
      "Epoch 58/100\n",
      "455/455 [==============================] - 676s 1s/step - loss: 0.7287 - accuracy: 0.7401 - val_loss: 1.0224 - val_accuracy: 0.6579\n",
      "Epoch 59/100\n",
      "455/455 [==============================] - 689s 2s/step - loss: 0.7044 - accuracy: 0.7502 - val_loss: 1.0568 - val_accuracy: 0.6523\n",
      "Epoch 60/100\n",
      "455/455 [==============================] - 686s 2s/step - loss: 0.7060 - accuracy: 0.7543 - val_loss: 1.0352 - val_accuracy: 0.6625\n",
      "Epoch 61/100\n",
      "455/455 [==============================] - 676s 1s/step - loss: 0.6960 - accuracy: 0.7579 - val_loss: 1.0835 - val_accuracy: 0.6585\n",
      "Epoch 62/100\n",
      "455/455 [==============================] - 678s 1s/step - loss: 0.6855 - accuracy: 0.7621 - val_loss: 1.1059 - val_accuracy: 0.6567\n",
      "Epoch 63/100\n",
      "455/455 [==============================] - 672s 1s/step - loss: 0.6858 - accuracy: 0.7624 - val_loss: 1.0452 - val_accuracy: 0.6576\n",
      "Epoch 64/100\n",
      "455/455 [==============================] - 696s 2s/step - loss: 0.6824 - accuracy: 0.7614 - val_loss: 1.0452 - val_accuracy: 0.6647\n",
      "Epoch 65/100\n",
      "455/455 [==============================] - 682s 1s/step - loss: 0.6765 - accuracy: 0.7660 - val_loss: 1.0642 - val_accuracy: 0.6678\n",
      "Epoch 66/100\n",
      "455/455 [==============================] - 681s 1s/step - loss: 0.6627 - accuracy: 0.7658 - val_loss: 1.0484 - val_accuracy: 0.6644\n",
      "Epoch 67/100\n",
      "455/455 [==============================] - 678s 1s/step - loss: 0.6583 - accuracy: 0.7696 - val_loss: 1.0958 - val_accuracy: 0.6576\n",
      "Epoch 68/100\n",
      "455/455 [==============================] - 675s 1s/step - loss: 0.6393 - accuracy: 0.7788 - val_loss: 1.1144 - val_accuracy: 0.6554\n",
      "Epoch 69/100\n",
      "455/455 [==============================] - 674s 1s/step - loss: 0.6426 - accuracy: 0.7749 - val_loss: 1.0687 - val_accuracy: 0.6625\n",
      "Epoch 70/100\n",
      "455/455 [==============================] - 682s 1s/step - loss: 0.6401 - accuracy: 0.7770 - val_loss: 1.0689 - val_accuracy: 0.6604\n",
      "Epoch 71/100\n",
      "455/455 [==============================] - 675s 1s/step - loss: 0.6287 - accuracy: 0.7827 - val_loss: 1.0797 - val_accuracy: 0.6613\n",
      "Epoch 72/100\n",
      "455/455 [==============================] - 672s 1s/step - loss: 0.6194 - accuracy: 0.7853 - val_loss: 1.0766 - val_accuracy: 0.6659\n",
      "Epoch 73/100\n",
      "455/455 [==============================] - 682s 1s/step - loss: 0.6205 - accuracy: 0.7869 - val_loss: 1.0940 - val_accuracy: 0.6567\n",
      "Epoch 74/100\n",
      "455/455 [==============================] - 680s 1s/step - loss: 0.6096 - accuracy: 0.7894 - val_loss: 1.0396 - val_accuracy: 0.6650\n",
      "Epoch 75/100\n",
      "455/455 [==============================] - 683s 2s/step - loss: 0.6138 - accuracy: 0.7884 - val_loss: 1.0711 - val_accuracy: 0.6628\n",
      "Epoch 76/100\n",
      "455/455 [==============================] - 681s 1s/step - loss: 0.5964 - accuracy: 0.7940 - val_loss: 1.1198 - val_accuracy: 0.6656\n",
      "Epoch 77/100\n",
      "455/455 [==============================] - 682s 1s/step - loss: 0.5985 - accuracy: 0.7963 - val_loss: 1.1360 - val_accuracy: 0.6604\n",
      "Epoch 78/100\n",
      "455/455 [==============================] - 680s 1s/step - loss: 0.6002 - accuracy: 0.7963 - val_loss: 1.0723 - val_accuracy: 0.6656\n",
      "Epoch 79/100\n",
      "455/455 [==============================] - 681s 1s/step - loss: 0.5852 - accuracy: 0.7982 - val_loss: 1.1227 - val_accuracy: 0.6607\n",
      "Epoch 80/100\n",
      "455/455 [==============================] - 689s 2s/step - loss: 0.5767 - accuracy: 0.8023 - val_loss: 1.1059 - val_accuracy: 0.6656\n",
      "Epoch 81/100\n",
      "455/455 [==============================] - 697s 2s/step - loss: 0.5680 - accuracy: 0.8039 - val_loss: 1.1226 - val_accuracy: 0.6737\n",
      "Epoch 82/100\n",
      "455/455 [==============================] - 683s 2s/step - loss: 0.5647 - accuracy: 0.8087 - val_loss: 1.1266 - val_accuracy: 0.6644\n",
      "Epoch 83/100\n",
      "455/455 [==============================] - 681s 1s/step - loss: 0.5602 - accuracy: 0.8121 - val_loss: 1.1322 - val_accuracy: 0.6684\n",
      "Epoch 84/100\n",
      "455/455 [==============================] - 684s 2s/step - loss: 0.5449 - accuracy: 0.8134 - val_loss: 1.1215 - val_accuracy: 0.6669\n",
      "Epoch 85/100\n",
      "455/455 [==============================] - 687s 2s/step - loss: 0.5517 - accuracy: 0.8129 - val_loss: 1.1067 - val_accuracy: 0.6684\n",
      "Epoch 86/100\n",
      "455/455 [==============================] - 685s 2s/step - loss: 0.5412 - accuracy: 0.8190 - val_loss: 1.1302 - val_accuracy: 0.6684\n",
      "Epoch 87/100\n",
      "455/455 [==============================] - 685s 2s/step - loss: 0.5464 - accuracy: 0.8162 - val_loss: 1.1757 - val_accuracy: 0.6594\n",
      "Epoch 88/100\n",
      "455/455 [==============================] - 693s 2s/step - loss: 0.5251 - accuracy: 0.8206 - val_loss: 1.1500 - val_accuracy: 0.6703\n",
      "Epoch 89/100\n",
      "455/455 [==============================] - 686s 2s/step - loss: 0.5341 - accuracy: 0.8179 - val_loss: 1.1870 - val_accuracy: 0.6749\n",
      "Epoch 90/100\n",
      "455/455 [==============================] - 686s 2s/step - loss: 0.5236 - accuracy: 0.8234 - val_loss: 1.1616 - val_accuracy: 0.6607\n",
      "Epoch 91/100\n",
      "455/455 [==============================] - 694s 2s/step - loss: 0.5168 - accuracy: 0.8275 - val_loss: 1.1992 - val_accuracy: 0.6675\n",
      "Epoch 92/100\n",
      "455/455 [==============================] - 685s 2s/step - loss: 0.5103 - accuracy: 0.8265 - val_loss: 1.1923 - val_accuracy: 0.6693\n",
      "Epoch 93/100\n",
      "455/455 [==============================] - 692s 2s/step - loss: 0.5062 - accuracy: 0.8280 - val_loss: 1.2059 - val_accuracy: 0.6690\n",
      "Epoch 94/100\n",
      "455/455 [==============================] - 689s 2s/step - loss: 0.5016 - accuracy: 0.8323 - val_loss: 1.1842 - val_accuracy: 0.6604\n",
      "Epoch 95/100\n",
      "455/455 [==============================] - 688s 2s/step - loss: 0.5016 - accuracy: 0.8334 - val_loss: 1.2007 - val_accuracy: 0.6613\n",
      "Epoch 96/100\n",
      "455/455 [==============================] - 692s 2s/step - loss: 0.4997 - accuracy: 0.8308 - val_loss: 1.1736 - val_accuracy: 0.6728\n",
      "Epoch 97/100\n",
      "455/455 [==============================] - 694s 2s/step - loss: 0.4926 - accuracy: 0.8366 - val_loss: 1.2225 - val_accuracy: 0.6625\n",
      "Epoch 98/100\n",
      "455/455 [==============================] - 683s 2s/step - loss: 0.4808 - accuracy: 0.8369 - val_loss: 1.2245 - val_accuracy: 0.6672\n",
      "Epoch 99/100\n",
      "455/455 [==============================] - 687s 2s/step - loss: 0.4766 - accuracy: 0.8398 - val_loss: 1.1896 - val_accuracy: 0.6635\n",
      "Epoch 100/100\n",
      "455/455 [==============================] - 682s 1s/step - loss: 0.4778 - accuracy: 0.8408 - val_loss: 1.1747 - val_accuracy: 0.6663\n",
      "Saved model\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=categorical_crossentropy,\n",
    "              optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-7),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#training the model\n",
    "model.fit(np.array(X_train), np.array(y_train),\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(np.array(X_valid), np.array(y_valid)),\n",
    "          shuffle=True)\n",
    "\n",
    "#saving the  model to be used later\n",
    "emotions_json = model.to_json()\n",
    "with open(\"emotions.json\", \"w\") as json_file:\n",
    "    json_file.write(emotions_json)\n",
    "model.save_weights(\"emotionCNN.h5\")\n",
    "print(\"Saved model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9012ed08",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = os.listdir(\"/Users/riley/Documents/Python Documents/ArtificialIntelligence/SemesterProject/faces\")\n",
    "test_df = pd.DataFrame({'filename' : filenames})    \n",
    "samples = test_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "147abe66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "test_data = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_data.flow_from_dataframe(\n",
    "    test_df, \n",
    "    \"/Users/riley/Documents/Python Documents/ArtificialIntelligence/SemesterProject/faces\", \n",
    "    x_col='filename',\n",
    "    y_col=None,\n",
    "    class_mode=None,\n",
    "    target_size=[48,488],\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0114c2b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "predict_generator() got an unexpected keyword argument 'input_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/by/b678j84n2sx8v1jwfplvm8jc0000gn/T/ipykernel_5431/4281457172.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: predict_generator() got an unexpected keyword argument 'input_shape'"
     ]
    }
   ],
   "source": [
    "predict = model.predict_generator(test_generator, steps=np.ceil(samples/batch_size), input_shape = (height, width, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c71133",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
